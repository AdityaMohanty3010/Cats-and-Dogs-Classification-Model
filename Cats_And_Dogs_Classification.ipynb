{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPV/QdVDTQsrZkPhdvCg8lD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaMohanty3010/Cats-and-Dogs-Classification-Model/blob/main/Cats_And_Dogs_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayk8tH_xzDGe",
        "outputId": "a6845186-7ade-43cf-ef33-6cca69e42efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Training SVM...\n",
            "SVM training completed and saved.\n",
            "Training Random Forest...\n",
            "Random Forest training completed and saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "dataset_path = \"cats_and_dogs.zip\"\n",
        "\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url)\n",
        "    with open(dataset_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    # Extract dataset\n",
        "    with ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"dataset\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_image(image_path, size=(16, 16)):  # Reduced size for faster processing\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, size)\n",
        "        image = image / 255.0  # Normalize\n",
        "        return image\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def load_data(data_dir, label_map, subset_size=None):\n",
        "    images, labels = [], []\n",
        "    for label, folder in label_map.items():\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for i, filename in enumerate(os.listdir(folder_path)):\n",
        "            if subset_size and i >= subset_size:\n",
        "                break\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            image = preprocess_image(file_path)\n",
        "            if image is not None:\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load data\n",
        "data_dir = \"dataset/PetImages\"\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "subset_size = 5000  # Use a subset for faster training\n",
        "images, labels = load_data(data_dir, label_map, subset_size=subset_size)\n",
        "\n",
        "# Flatten images for ML models (non-CNN models)\n",
        "flattened_images = images.reshape(len(images), -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "y_categorical = to_categorical(encoded_labels)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "cnn_X_train, cnn_X_test, cnn_y_train, cnn_y_test = train_test_split(images, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "print(\"Training SVM...\")\n",
        "svm_model = SVC(kernel='linear', C=0.1, probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "print(\"SVM training completed and saved.\")\n",
        "\n",
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "joblib.dump(rf_model, \"rf_model.pkl\")\n",
        "print(\"Random Forest training completed and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Logistic Regression (SGD)\n",
        "print(\"Training Logistic Regression...\")\n",
        "sgd_model = SGDClassifier(loss='log_loss', max_iter=1000, random_state=42)  # Updated loss parameter\n",
        "sgd_model.fit(X_train, y_train)\n",
        "joblib.dump(sgd_model, \"sgd_model.pkl\")\n",
        "print(\"Logistic Regression training completed and saved.\")\n",
        "\n",
        "\n",
        "# Train CNN\n",
        "print(\"Training CNN...\")\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(16, 16, 3)),  # Fewer filters\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),  # Smaller dense layer\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(cnn_X_train, cnn_y_train, epochs=30, batch_size=64, validation_data=(cnn_X_test, cnn_y_test))  # Fewer epochs\n",
        "cnn_model.save(\"cnn_model.h5\")\n",
        "print(\"CNN training completed and saved.\")\n",
        "\n",
        "# Load models for inference\n",
        "print(\"Loading models for inference...\")\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "\n",
        "# Test on one sample image\n",
        "sample_image = X_test[0].reshape(1, -1)  # For non-CNN models\n",
        "cnn_sample_image = cnn_X_test[0].reshape(1, 16, 16, 3)  # For CNN\n",
        "\n",
        "print(\"SVM Prediction:\", label_encoder.inverse_transform(svm_model.predict(sample_image)))\n",
        "print(\"Random Forest Prediction:\", label_encoder.inverse_transform(rf_model.predict(sample_image)))\n",
        "print(\"Logistic Regression Prediction:\", label_encoder.inverse_transform(sgd_model.predict(sample_image)))\n",
        "print(\"CNN Prediction:\", label_encoder.inverse_transform(np.argmax(cnn_model.predict(cnn_sample_image), axis=1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "purgnjNc0ncK",
        "outputId": "539d72e8-0337-4153-c2fc-a231f1ce44b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression training completed and saved.\n",
            "Training CNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.5722 - loss: 0.6794 - val_accuracy: 0.6133 - val_loss: 0.6405\n",
            "Epoch 2/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.6010 - val_accuracy: 0.7031 - val_loss: 0.5748\n",
            "Epoch 3/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.5747 - val_accuracy: 0.7081 - val_loss: 0.5677\n",
            "Epoch 4/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.5595 - val_accuracy: 0.7061 - val_loss: 0.5658\n",
            "Epoch 5/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5432 - val_accuracy: 0.7277 - val_loss: 0.5438\n",
            "Epoch 6/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.5250 - val_accuracy: 0.7232 - val_loss: 0.5497\n",
            "Epoch 7/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5142 - val_accuracy: 0.7066 - val_loss: 0.5635\n",
            "Epoch 8/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.5060 - val_accuracy: 0.7382 - val_loss: 0.5304\n",
            "Epoch 9/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.4881 - val_accuracy: 0.7302 - val_loss: 0.5451\n",
            "Epoch 10/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4637 - val_accuracy: 0.7282 - val_loss: 0.5485\n",
            "Epoch 11/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4517 - val_accuracy: 0.7392 - val_loss: 0.5309\n",
            "Epoch 12/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4362 - val_accuracy: 0.7257 - val_loss: 0.5449\n",
            "Epoch 13/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4171 - val_accuracy: 0.7372 - val_loss: 0.5377\n",
            "Epoch 14/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.3963 - val_accuracy: 0.7387 - val_loss: 0.5423\n",
            "Epoch 15/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3689 - val_accuracy: 0.7247 - val_loss: 0.5617\n",
            "Epoch 16/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3574 - val_accuracy: 0.7272 - val_loss: 0.5784\n",
            "Epoch 17/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3352 - val_accuracy: 0.7081 - val_loss: 0.6082\n",
            "Epoch 18/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3290 - val_accuracy: 0.7302 - val_loss: 0.5685\n",
            "Epoch 19/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2922 - val_accuracy: 0.7277 - val_loss: 0.5955\n",
            "Epoch 20/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2729 - val_accuracy: 0.7267 - val_loss: 0.6019\n",
            "Epoch 21/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2536 - val_accuracy: 0.7327 - val_loss: 0.6232\n",
            "Epoch 22/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2286 - val_accuracy: 0.7252 - val_loss: 0.6717\n",
            "Epoch 23/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2156 - val_accuracy: 0.7227 - val_loss: 0.6798\n",
            "Epoch 24/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2089 - val_accuracy: 0.7222 - val_loss: 0.6767\n",
            "Epoch 25/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.1813 - val_accuracy: 0.7036 - val_loss: 0.7345\n",
            "Epoch 26/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.1811 - val_accuracy: 0.7307 - val_loss: 0.7042\n",
            "Epoch 27/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1463 - val_accuracy: 0.7187 - val_loss: 0.7497\n",
            "Epoch 28/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.1321 - val_accuracy: 0.7232 - val_loss: 0.7931\n",
            "Epoch 29/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.1238 - val_accuracy: 0.7242 - val_loss: 0.7849\n",
            "Epoch 30/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.1036 - val_accuracy: 0.7096 - val_loss: 0.8200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN training completed and saved.\n",
            "Loading models for inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Prediction: [0]\n",
            "Random Forest Prediction: [1]\n",
            "Logistic Regression Prediction: [1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "CNN Prediction: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train K-Means\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress warnings for clean outpu\n",
        "print(\"Training K-Means...\")\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans_model.fit(X_train)  # Unsupervised training on flattened images\n",
        "joblib.dump(kmeans_model, \"kmeans_model.pkl\")\n",
        "print(\"K-Means training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBmkSJe31Fdq",
        "outputId": "c2819b5f-3735-4e37-e39e-1f864fc627b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training K-Means...\n",
            "K-Means training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok flask tensorflow scikit-learn pillow #1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFTqvX4JRmVz",
        "outputId": "76b653d0-a239-44b2-92e5-a1db111a6af6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyter-dash #2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbPHrBkRRtyd",
        "outputId": "2c89224b-1865-40a9-e459-464f032a82f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter-dash\n",
            "  Downloading jupyter_dash-0.4.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dash (from jupyter-dash)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (2.32.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (3.1.0)\n",
            "Collecting retrying (from jupyter-dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (5.5.6)\n",
            "Collecting ansi2html (from jupyter-dash)\n",
            "  Downloading ansi2html-1.9.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Collecting flask (from jupyter-dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash->jupyter-dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.3.3)\n",
            "Collecting jedi>=0.16 (from ipython->jupyter-dash)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->jupyter-dash) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask->jupyter-dash) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash->jupyter-dash) (3.21.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (4.3.6)\n",
            "Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
            "Downloading ansi2html-1.9.2-py3-none-any.whl (17 kB)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, jedi, ansi2html, flask, dash, jupyter-dash\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Werkzeug-3.0.6 ansi2html-1.9.2 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-3.0.3 jedi-0.19.2 jupyter-dash-0.4.2 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash   #3\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output# Load Data"
      ],
      "metadata": {
        "id": "UJ7RFL_jRxgY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyngrok  #4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgSf8PGTR8_l",
        "outputId": "8689b3c7-a19a-4aeb-c18a-70750e816dc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask #5\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "l8PoJoqPR_Ey"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('2rtAXV6cMpS1rLfxIPVOlkSdUBj_2RSnhNvqb6o7FGjZpgq1e')\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(public_url) #6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPI8OTKcSECX",
        "outputId": "7a925230-ba28-4e91-f2fa-1ee580ab5c6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5e81-34-83-235-79.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, render_template\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pyngrok import ngrok      #7\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set up ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Load models\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "kmeans_model = joblib.load(\"kmeans_model.pkl\")  # Load KMeans model\n",
        "\n",
        "# Label map\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "\n",
        "def inverse_label(label_idx):\n",
        "    return label_map[label_idx]\n",
        "\n",
        "# Preprocess image\n",
        "def preprocess_image(image_file, size=(16, 16)):\n",
        "    image = cv2.imdecode(np.frombuffer(image_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        return None\n",
        "    image = cv2.resize(image, size)\n",
        "    image = image / 255.0  # Normalize\n",
        "    return image\n",
        "\n",
        "# Root route\n",
        "# Root route\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Cat and Dog Classifier</title>\n",
        "            <style>\n",
        "                body {\n",
        "                    font-family: 'Arial', sans-serif;\n",
        "                    background-color: #f7f7f7;\n",
        "                    color: #333;\n",
        "                    margin: 0;\n",
        "                    padding: 0;\n",
        "                    display: flex;\n",
        "                    justify-content: center;\n",
        "                    align-items: center;\n",
        "                    height: 100vh;\n",
        "                    flex-direction: column;\n",
        "                }\n",
        "\n",
        "                h1 {\n",
        "                    font-size: 3em;\n",
        "                    color: #3b3b3b;\n",
        "                    margin-bottom: 30px;\n",
        "                    text-align: center;\n",
        "                }\n",
        "\n",
        "                .container {\n",
        "                    background-color: #ffffff;\n",
        "                    border-radius: 8px;\n",
        "                    padding: 40px;\n",
        "                    box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.1);\n",
        "                    text-align: center;\n",
        "                    width: 350px;\n",
        "                    max-width: 100%;\n",
        "                }\n",
        "\n",
        "                .container input[type=\"file\"] {\n",
        "                    padding: 10px;\n",
        "                    margin: 20px 0;\n",
        "                    font-size: 1.1em;\n",
        "                    border: 2px solid #ddd;\n",
        "                    border-radius: 5px;\n",
        "                    width: 100%;\n",
        "                    box-sizing: border-box;\n",
        "                    cursor: pointer;\n",
        "                }\n",
        "\n",
        "                .container button {\n",
        "                    padding: 12px 30px;\n",
        "                    font-size: 1.2em;\n",
        "                    background-color: #5C6BC0;\n",
        "                    color: white;\n",
        "                    border: none;\n",
        "                    border-radius: 5px;\n",
        "                    cursor: pointer;\n",
        "                    transition: background-color 0.3s;\n",
        "                    margin-top: 10px;\n",
        "                }\n",
        "\n",
        "                .container button:hover {\n",
        "                    background-color: #3f51b5;\n",
        "                }\n",
        "\n",
        "                .result {\n",
        "                    margin-top: 20px;\n",
        "                    padding: 15px;\n",
        "                    background-color: #e3f2fd;\n",
        "                    border-radius: 5px;\n",
        "                }\n",
        "\n",
        "                img {\n",
        "                    margin-top: 20px;\n",
        "                    max-width: 100%;\n",
        "                    border-radius: 8px;\n",
        "                    box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.1);\n",
        "                }\n",
        "\n",
        "                footer {\n",
        "                    margin-top: 40px;\n",
        "                    font-size: 0.9em;\n",
        "                    color: #777;\n",
        "                }\n",
        "\n",
        "                footer a {\n",
        "                    color: #5C6BC0;\n",
        "                    text-decoration: none;\n",
        "                }\n",
        "\n",
        "                footer a:hover {\n",
        "                    text-decoration: underline;\n",
        "                }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>Cat and Dog Classifier</h1>\n",
        "            <div class=\"container\">\n",
        "                <form id=\"predictForm\" enctype=\"multipart/form-data\">\n",
        "                    <label for=\"image\">\n",
        "                        <strong>Upload an image of a Cat or Dog:</strong>\n",
        "                    </label>\n",
        "                    <input type=\"file\" id=\"imageInput\" name=\"image\" accept=\"image/*\" required>\n",
        "                    <button type=\"submit\">Predict</button>\n",
        "                </form>\n",
        "\n",
        "                <div id=\"predictionResult\"></div>\n",
        "                <div id=\"imagePreview\"></div>\n",
        "            </div>\n",
        "\n",
        "            <footer>\n",
        "                <p>Created with ❤️ by Aditya Mohanty | <a href=\"https://github.com/AdityaMohanty3010\">View on GitHub</a></p>\n",
        "            </footer>\n",
        "\n",
        "            <script>\n",
        "                document.getElementById('predictForm').addEventListener('submit', function(event) {\n",
        "                    event.preventDefault();  // Prevent page refresh\n",
        "\n",
        "                    const formData = new FormData(this);\n",
        "                    const imageInput = document.getElementById('imageInput');\n",
        "                    const imagePreview = document.getElementById('imagePreview');\n",
        "                    const predictionResult = document.getElementById('predictionResult');\n",
        "\n",
        "                    // Display the image preview\n",
        "                    const file = imageInput.files[0];\n",
        "                    const reader = new FileReader();\n",
        "                    reader.onload = function(e) {\n",
        "                        imagePreview.innerHTML = `<img src=\"${e.target.result}\" alt=\"Image Preview\">`;\n",
        "                    };\n",
        "                    reader.readAsDataURL(file);\n",
        "\n",
        "                    // AJAX request to send the image to the server\n",
        "                    const xhr = new XMLHttpRequest();\n",
        "                    xhr.open('POST', '/predict', true);\n",
        "                    xhr.onreadystatechange = function() {\n",
        "                        if (xhr.readyState == 4 && xhr.status == 200) {\n",
        "                            const response = JSON.parse(xhr.responseText);\n",
        "\n",
        "                            // Display predictions\n",
        "                            predictionResult.innerHTML = `\n",
        "                                <div class=\"result\">\n",
        "                                    <h3>Predictions:</h3>\n",
        "                                    <p><strong>SVM Prediction:</strong> ${response.svm_prediction}</p>\n",
        "                                    <p><strong>Random Forest Prediction:</strong> ${response.rf_prediction}</p>\n",
        "                                    <p><strong>SGD Prediction:</strong> ${response.sgd_prediction}</p>\n",
        "                                    <p><strong>CNN Prediction:</strong> ${response.cnn_prediction}</p>\n",
        "                                    <p><strong>KMeans Prediction:</strong> ${response.kmeans_prediction}</p>\n",
        "                                </div>\n",
        "                            `;\n",
        "                        }\n",
        "                    };\n",
        "\n",
        "                    xhr.send(formData);\n",
        "                });\n",
        "            </script>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# Prediction route\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image uploaded'}), 400\n",
        "\n",
        "    image_file = request.files['image']\n",
        "    image = preprocess_image(image_file)\n",
        "\n",
        "    if image is None:\n",
        "        return jsonify({'error': 'Invalid image format'}), 400\n",
        "\n",
        "    # Flatten image for non-CNN models\n",
        "    flattened_image = image.reshape(1, -1)\n",
        "\n",
        "    # CNN requires a 4D tensor\n",
        "    cnn_image = image.reshape(1, 16, 16, 3)\n",
        "\n",
        "    # Make predictions\n",
        "    svm_prediction = inverse_label(svm_model.predict(flattened_image)[0])\n",
        "    rf_prediction = inverse_label(rf_model.predict(flattened_image)[0])\n",
        "    sgd_prediction = inverse_label(sgd_model.predict(flattened_image)[0])\n",
        "    cnn_prediction = inverse_label(np.argmax(cnn_model.predict(cnn_image), axis=1)[0])\n",
        "\n",
        "    # KMeans prediction (returns cluster number)\n",
        "    kmeans_cluster = kmeans_model.predict(flattened_image)[0]\n",
        "    kmeans_prediction = f\"Cluster {kmeans_cluster}\"\n",
        "\n",
        "    return jsonify({\n",
        "        'svm_prediction': svm_prediction,\n",
        "        'rf_prediction': rf_prediction,\n",
        "        'sgd_prediction': sgd_prediction,\n",
        "        'cnn_prediction': cnn_prediction,\n",
        "        'kmeans_prediction': kmeans_prediction\n",
        "    })\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLw8-rqxSUBE",
        "outputId": "11fe8bc0-98bc-48b5-c50b-f637d17f5770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://661d-34-83-235-79.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 14:53:00] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 14:53:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 14:53:08] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}